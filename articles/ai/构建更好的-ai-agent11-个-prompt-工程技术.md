---
layout: post
title: "构建更好的 AI Agent：11 个 Prompt 工程技术"
date: 2026-02-19
categories: ai
tags: ["AI", "Agent", "Prompt Engineering", "最佳实践"]
permalink: /ai/构建更好的-ai-agent11-个-prompt-工程技术/
---

# 构建更好的 AI Agent：11 个 Prompt 工程技术

**原文**: [Augment Code Blog](https://www.augmentcode.com/blog/how-to-build-your-agent-11-prompting-techniques-for-better-ai-agents)  
**整理时间**: 2026-02-19

---

## 引言

Prompt 工程已成为现代软件开发中最高杠杆的技能之一。你提供给 Agent 的 Prompt 决定了它如何规划、如何使用工具，以及它是构建还是破坏你的流程。

微小的改变——额外的一行上下文、一个明确的约束、一个重新排序的指令——往往能在准确性和可靠性方面产生巨大的收益。

本文总结了 Augment Code 团队在实际项目中使用的、经过实战检验的战术，用于构建像自律的团队成员一样工作的自主 Agent，而不是产生幻觉的 vibe coding 工具。

---

## 什么是 Prompt 工程？

Agent 的 Prompt 包括作为输入提供给模型的所有内容：

- **System prompt**（系统提示）
- **Tool definitions**（工具定义）
- **Tool outputs**（工具输出）
- **User instructions**（用户指令）
- **模型自己之前的输出**

Prompt 工程是通过提供更好的 Prompt 来提高模型在任务上表现的艺术。Prompt 的所有部分都可以潜在地通过 Prompt 工程进行改进。

---

## 11 个 Prompt 工程技术

### 1. 首先关注上下文

Prompt 工程中最重要的因素是为模型提供**尽可能好的上下文**：用户提供的信息（而不是我们提供的 Prompt 文本）。这是模型执行任务的主要信号。

当前模型擅长在大型 Prompt 中找到有用的相关上下文片段，因此当你有疑问时，倾向于提供更多信息，如果这能增加上下文包含有用相关信息的可能性。

**关于 Prompt 的第一个问题应该是**——它是否包含所有相关信息，概率是多少？回答这个问题并不总是简单的。

**💡 示例**: 当截断长命令输出以提供给模型时，截断方法很重要。通常，截断长文本涉及截断后缀。然而，对于命令输出，有用信息更可能出现在前缀和后缀而不是中间。例如，崩溃的堆栈跟踪通常出现在后缀中。因此，为了最大化模型获得最相关上下文的可能性，最好截断命令输出的中间部分而不是后缀。

---

### 2. 呈现完整的世界图景

通过解释模型所处的环境并提供可能有助于其表现良好的细节，帮助模型进入正确的状态。例如，如果你想让模型充当软件开发人员，在系统 Prompt 中告诉它。向它解释它可以访问哪些资源以及如何使用它们。

例如，这两行在 Augment Agent 开发早期被引入到系统 Prompt 中，显著提高了其性能：

```
The current directory is $CWD
```

---

### 3. 保持 Prompt 组件的一致性

确保 Prompt 的所有组件（系统 Prompt、工具定义等）以及底层工具定义都是一致的。

**💡 示例**:
- 系统 Prompt 包含 "The current directory is $CWD"
- `execute_command` 工具（允许 Agent 执行 shell 命令）包含一个可选的 `cwd` 参数。一致性意味着该参数的默认值应该是 `$CWD`。这可以在工具定义中指定。如果没有，模型可能会假设情况就是这样。
- `read_file` 工具接受要读取的文件的路径参数。如果提供相对路径，应该解释为相对于 `$CWD`。

**⚠️ 注意**: 避免让模型感到惊讶。模型很容易被混淆。如果模型可能期望工具调用产生某个结果，请确保要么提供该结果，要么在工具结果中解释偏差。例如，如果工具定义承诺返回一定长度的输出，要么返回该长度的输出，要么在答案前加上类似 "Output of length N was requested, but returning output of length K instead because ..." 的声明。

---

### 4. 将模型与用户的视角对齐

考虑用户的视角，并尝试将模型与该视角对齐。

**💡 示例**: 当用户在 IDE 中工作时，可以向模型展示 IDE 状态的详细视图，专注于用户最可能关心的元素，或在他们的指令中引用的元素。

**可能有助于对齐模型的信息**:
- 用户的当前时间和时区
- 用户的当前位置
- 用户的活动历史

---

### 5. 利用模型的智能

模型是（人工）智能的。给模型 Prompt 更接近于与人交谈，而不是给计算机编程。模型构建的世界观完全基于 Prompt 中的内容。Prompt 越完整和一致，模型的结果就越好。

模型向我们呈现了一个自然语言界面，这与我们工作的编程语言是分开的。将 LM 界面视为一个独立但真实的抽象层是有用的。这个界面可以用来呈现快乐路径的结果，但也可以用来警告错误、通知更改等——一般来说就是与模型通信。

**💡 示例**: 如果模型错误地调用了工具，不要在你的 Agent 代码中抛出异常。相反，返回一个解释错误是什么的工具结果："Tool was called without required parameter xyz"。模型会恢复并重试。

---

### 6. 在工具定义中解释边缘情况

工具定义可以向模型解释在什么情况下应该或不应该使用工具。

**💡 示例**: `read_file` 工具接受文件的路径。如果提供相对路径，它应该被解释为相对于 `$CWD`。

---

### 7. 处理状态变化

如果 Prompt 包含可能在会话期间发生变化的状态（例如当前时间），不要将它们包含在系统 Prompt 或工具定义中。相反，在下一条用户消息中告诉模型变化。这保持了 Prompt 的内部一致性：模型可以看到在每个回合时状态是什么。

---

### 8. 评估你的 Prompt

通常很难自动评估 Prompt，除非目标是让模型执行非常具体的任务。尝试想出以各种方式测试 Prompt 的场景，并尝试找到 Prompt 更改可能导致回归的示例。

这些评估原则的实际应用示例，可以看看相同的 Prompt 工程技术如何推动 Augment Code 在 SWE-bench 上达到 [#1 开源分数](https://www.augmentcode.com/blog/1-open-source-agent-on-swe-bench-verified-by-combining-claude-3-7-and-o1)。

---

### 9. 压缩或截断历史对话

模型自己之前的输出可以被压缩或截断以节省 token，因此更长的对话历史可以适应上下文窗口。如何截断对质量很重要。

---

### 10. 重写用户指令（Prompt 增强）

用户指令可以在展示给模型之前被重写。这称为 Prompt 增强。

---

### 11. 建立反馈循环

当模型犯错时，不要只是报错，而是提供有用的反馈，让模型能够学习和改进。这创造了一个反馈循环，使模型随时间变得更好。

---

## 总结

这些技术帮助 Augment Code 构建了能够像自律的团队成员一样工作的 Agent。遵循这些技巧，你将释放出 AGI 的潜力。

**核心要点**:
1. 上下文 > Prompt 文本
2. 保持一致性
3. 呈现完整图景
4. 与用户视角对齐
5. 利用模型的智能

---

*原文作者: Augment Code*  
*整理: AI Digests*